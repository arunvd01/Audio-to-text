{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1787a37d-6328-44b4-bc03-ec19eef1933f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyaudio in c:\\users\\arunv\\anaconda3\\lib\\site-packages (0.2.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c07ddff-13a4-4f0e-88ac-dba99de5bba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 6 seconds...\n",
      "Recording finished.\n",
      "Audio saved to output.wav\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "def record_audio(output_filename, duration, sample_rate=44100, chunk_size=1024):\n",
    "    \"\"\"\n",
    "    Records live audio from the microphone and saves it to a .wav file.\n",
    "\n",
    "    Args:\n",
    "        output_filename (str): The name of the output WAV file.\n",
    "        duration (int): Duration of the recording in seconds.\n",
    "        sample_rate (int): The sample rate of the recording (default is 44100 Hz).\n",
    "        chunk_size (int): The size of each audio chunk (default is 1024).\n",
    "    \"\"\"\n",
    "    # Initialize PyAudio\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Set audio stream parameters\n",
    "    stream = audio.open(\n",
    "        format=pyaudio.paInt16,  # 16-bit resolution\n",
    "        channels=1,             # Mono audio\n",
    "        rate=sample_rate,       # Sampling rate\n",
    "        input=True,             # Use input device\n",
    "        frames_per_buffer=chunk_size  # Buffer size\n",
    "    )\n",
    "\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "\n",
    "    frames = []  # List to store audio chunks\n",
    "\n",
    "    # Record audio\n",
    "    for _ in range(0, int(sample_rate / chunk_size * duration)):\n",
    "        data = stream.read(chunk_size)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    with wave.open(output_filename, \"wb\") as wf:\n",
    "        wf.setnchannels(1)  # Mono audio\n",
    "        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "\n",
    "    print(f\"Audio saved to {output_filename}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    output_file = \"output.wav\"\n",
    "    record_duration = 6  # Record for 5 seconds\n",
    "    record_audio(output_file, record_duration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b9341cd8-c306-4ace-b4a6-4aa9fbb0147d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 5 seconds...\n",
      "Recording finished.\n",
      "Audio saved to output.wav\n",
      "Processing audio...\n",
      "Transcribed Text:\n",
      "Speech not recognized.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "\n",
    "def record_audio(output_filename, duration, sample_rate=44100, chunk_size=1024):\n",
    "    \"\"\"\n",
    "    Records live audio from the microphone and saves it to a .wav file.\n",
    "\n",
    "    Args:\n",
    "        output_filename (str): The name of the output WAV file.\n",
    "        duration (int): Duration of the recording in seconds.\n",
    "        sample_rate (int): The sample rate of the recording (default is 44100 Hz).\n",
    "        chunk_size (int): The size of each audio chunk (default is 1024).\n",
    "    \"\"\"\n",
    "    # Initialize PyAudio\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Set audio stream parameters\n",
    "    stream = audio.open(\n",
    "        format=pyaudio.paInt16,  # 16-bit resolution\n",
    "        channels=1,             # Mono audio\n",
    "        rate=sample_rate,       # Sampling rate\n",
    "        input=True,             # Use input device\n",
    "        frames_per_buffer=chunk_size  # Buffer size\n",
    "    )\n",
    "\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "\n",
    "    frames = []  # List to store audio chunks\n",
    "\n",
    "    # Record audio\n",
    "    for _ in range(0, int(sample_rate / chunk_size * duration)):\n",
    "        data = stream.read(chunk_size)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    with wave.open(output_filename, \"wb\") as wf:\n",
    "        wf.setnchannels(1)  # Mono audio\n",
    "        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "\n",
    "    print(f\"Audio saved to {output_filename}\")\n",
    "\n",
    "\n",
    "def audio_to_text(audio_filename):\n",
    "    \"\"\"\n",
    "    Converts an audio file to text using the SpeechRecognition library.\n",
    "\n",
    "    Args:\n",
    "        audio_filename (str): Path to the audio file.\n",
    "\n",
    "    Returns:\n",
    "        str: Transcribed text.\n",
    "    \"\"\"\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Load the audio file\n",
    "    with sr.AudioFile(audio_filename) as source:\n",
    "        print(\"Processing audio...\")\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    # Recognize and return the text\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech not recognized.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from the API; {e}\"\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    output_file = \"output.wav\"\n",
    "    record_duration = 5  # Record for 5 seconds\n",
    "\n",
    "    # Record live audio\n",
    "    record_audio(output_file, record_duration)\n",
    "\n",
    "    # Convert recorded audio to text\n",
    "    transcribed_text = audio_to_text(output_file)\n",
    "    print(\"Transcribed Text:\")\n",
    "    print(transcribed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6c2535ef-de67-4e78-9b42-377e2326f7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording for 10 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\arunv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\arunv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\arunv\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording finished.\n",
      "Audio saved to output.wav\n",
      "Processing audio...\n",
      "\n",
      "Original Text:\n",
      "it is Arun Vijay from IPCS currently and studying NLP\n",
      "\n",
      "Tokens:\n",
      "['it', 'is', 'Arun', 'Vijay', 'from', 'IPCS', 'currently', 'and', 'studying', 'NLP']\n",
      "\n",
      "Filtered Tokens (No Stopwords):\n",
      "['Arun', 'Vijay', 'IPCS', 'currently', 'studying', 'NLP']\n",
      "\n",
      "Stemmed Tokens:\n",
      "['arun', 'vijay', 'ipc', 'current', 'studi', 'nlp']\n",
      "\n",
      "Lemmatized Tokens:\n",
      "['Arun', 'Vijay', 'IPCS', 'currently', 'studying', 'NLP']\n",
      "\n",
      "Vectorized Tokens (Feature Matrix):\n",
      "[[1 1 1 1 1 1]]\n",
      "\n",
      "Feature Names:\n",
      "['arun' 'currently' 'ipcs' 'nlp' 'studying' 'vijay']\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import nltk\n",
    "\n",
    "# Ensure NLTK data is downloaded\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def record_audio(output_filename, duration, sample_rate=44100, chunk_size=1024):\n",
    "    # Initialize PyAudio\n",
    "    audio = pyaudio.PyAudio()\n",
    "\n",
    "    # Set audio stream parameters\n",
    "    stream = audio.open(\n",
    "        format=pyaudio.paInt16,  # 16-bit resolution\n",
    "        channels=1,             # Mono audio\n",
    "        rate=sample_rate,       # Sampling rate\n",
    "        input=True,             # Use input device\n",
    "        frames_per_buffer=chunk_size  # Buffer size\n",
    "    )\n",
    "\n",
    "    print(f\"Recording for {duration} seconds...\")\n",
    "\n",
    "    frames = []  # List to store audio chunks\n",
    "\n",
    "    # Record audio\n",
    "    for _ in range(0, int(sample_rate / chunk_size * duration)):\n",
    "        data = stream.read(chunk_size)\n",
    "        frames.append(data)\n",
    "\n",
    "    print(\"Recording finished.\")\n",
    "\n",
    "    # Stop and close the stream\n",
    "    stream.stop_stream()\n",
    "    stream.close()\n",
    "    audio.terminate()\n",
    "\n",
    "    # Save the recorded audio to a WAV file\n",
    "    with wave.open(output_filename, \"wb\") as wf:\n",
    "        wf.setnchannels(1)  # Mono audio\n",
    "        wf.setsampwidth(audio.get_sample_size(pyaudio.paInt16))\n",
    "        wf.setframerate(sample_rate)\n",
    "        wf.writeframes(b\"\".join(frames))\n",
    "\n",
    "    print(f\"Audio saved to {output_filename}\")\n",
    "\n",
    "\n",
    "def audio_to_text(audio_filename):\n",
    "    recognizer = sr.Recognizer()\n",
    "\n",
    "    # Load the audio file\n",
    "    with sr.AudioFile(audio_filename) as source:\n",
    "        print(\"Processing audio...\")\n",
    "        audio_data = recognizer.record(source)\n",
    "\n",
    "    # Recognize and return the text\n",
    "    try:\n",
    "        text = recognizer.recognize_google(audio_data)\n",
    "        return text\n",
    "    except sr.UnknownValueError:\n",
    "        return \"Speech not recognized.\"\n",
    "    except sr.RequestError as e:\n",
    "        return f\"Could not request results from the API; {e}\"\n",
    "\n",
    "\n",
    "def apply_nlp(text):\n",
    "    print(\"\\nOriginal Text:\")\n",
    "    print(text)\n",
    "\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "    print(\"\\nTokens:\")\n",
    "    print(tokens)\n",
    "\n",
    "    # Stopword Removal\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
    "    print(\"\\nFiltered Tokens (No Stopwords):\")\n",
    "    print(filtered_tokens)\n",
    "\n",
    "    # Stemming\n",
    "    stemmer = PorterStemmer()\n",
    "    stemmed_tokens = [stemmer.stem(word) for word in filtered_tokens]\n",
    "    print(\"\\nStemmed Tokens:\")\n",
    "    print(stemmed_tokens)\n",
    "\n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_tokens = [lemmatizer.lemmatize(word) for word in filtered_tokens]\n",
    "    print(\"\\nLemmatized Tokens:\")\n",
    "    print(lemmatized_tokens)\n",
    "\n",
    "    # Vectorization\n",
    "    vectorizer = CountVectorizer()\n",
    "    vectorized_data = vectorizer.fit_transform([\" \".join(filtered_tokens)])\n",
    "    print(\"\\nVectorized Tokens (Feature Matrix):\")\n",
    "    print(vectorized_data.toarray())\n",
    "    print(\"\\nFeature Names:\")\n",
    "    print(vectorizer.get_feature_names_out())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Parameters\n",
    "    output_file = \"output.wav\"\n",
    "    record_duration = 10  # Record for 5 seconds\n",
    "\n",
    "    # Record live audio\n",
    "    record_audio(output_file, record_duration)\n",
    "\n",
    "    # Convert recorded audio to text\n",
    "    transcribed_text = audio_to_text(output_file)\n",
    "\n",
    "    # Apply NLP techniques\n",
    "    if transcribed_text:\n",
    "        apply_nlp(transcribed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc8be60-4b41-41dc-87ee-4857aa0e9c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
